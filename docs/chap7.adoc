== 神经网络BP反向传播算法原理和详细推导流程

=== 反向传播算法和BP网络简介

误差反向传播算法简称反向传播算法（即BP算法）。使用反向传播算法的多层感知器又称为BP神经网络。BP算法是一个迭代算法，它的基本思想为：

. 先计算每一层的状态和激活值，直到最后一层（即信号是前向传播的）；
. 计算每一层的误差，误差的计算过程是从最后一层向前推进的（这就是反向传播算法名字的由来）；
. 更新参数（目标是误差变小）。迭代前面两个步骤，直到满足停止准则（比如相邻两次迭代的误差的差别很小）。

本文的记号说明：

* stem:[n_l]表示第stem:[l]层神经元的个数；
* stem:[f(\cdot)]表示神经元的激活函数；
* stem:[W^{(l)} \in \mathbb{R}^{n_l \times n_{l-1}}]表示第stem:[l-1]层到第stem:[l]层的权重矩阵；
* stem:[w_{ij}^{(l)}]是权重矩阵stem:[W^{(l)}]中的元素，表示第stem:[l-1]层第stem:[j]个神经元到第stem:[l]层第stem:[i]个神经元的连接的权重（注意标号的顺序）；
* stem:[\textbf{b}^{(l)}=(b_1^{(l)},b_2^{(l)},\dots,b_{n_l}^{(l)})^T \in \mathbb{R}^{n_l}]表示stem:[l-1]层到第stem:[l]层的偏置；
* stem:[\textbf{z}^{(l)}=(z_1^{(l)},z_2^{(l)},\dots,z_{n_l}^{(l)})^T \in \mathbb{R}^{n_l}]表示stem:[l]层神经元的状态；
* stem:[\textbf{a}^{(l)}=(a_1^{(l)},a_2^{(l)},\dots,a_{n_l}^{(l)})^T \in \mathbb{R}^{n_l}]表示stem:[l]层神经元的激活值（即输出值）；

**关于记号的特别注意**：不同的文献所采用的记号可能不同，这将导致不同文献的公式结论可能不同。如Andrew Ng的教程中的stem:[W^{(l)}]表示的是第stem:[l]层到第stem:[l+1]层的权重矩阵。又如，本文用“下标”来标记一个向量的不同分量，而有一些资料却用“上标”来标记向量的不同分量。

下面以三层感知器(即只含有一个隐藏层的多层感知器)为例介绍“反向传播算法(BP算法)”。

三层感知机如图1所示。例子中，输入数据stem:[\textbf{x}=(x_1,x_2,x_3)^T]是3维的（对于第一层，可以认为stem:[a_i^{(1)}=x_i]），唯一的隐藏层有3个节点，输出数据是2维的。

image::dnn8.png[]

=== 信息前向传播

显然，图1所示神经网络的第2层神经元的状态及激活值可以通过下面的计算得到：

[stem]
++++
z_1^{(2)}=w_{11}^{(2)}x_1+w_{12}^{(2)}x_2+w_{13}^{(2)}x_3+b_1^{(2)} \\
z_2^{(2)}=w_{21}^{(2)}x_1+w_{22}^{(2)}x_2+w_{23}^{(2)}x_3+b_2^{(2)} \\
z_3^{(2)}=w_{31}^{(2)}x_1+w_{32}^{(2)}x_2+w_{33}^{(2)}x_3+b_3^{(2)} \\
a_1^{(2)}=f(z_1^{(2)}) \\
a_2^{(2)}=f(z_2^{(2)}) \\
a_3^{(2)}=f(z_3^{(2)})
++++

类似的，第3层神经元的状态及激活值可以通过下面的计算得到：

[stem]
++++
z_1^{(3)}=w_{11}^{(3)}a_1^{(2)}+w_{12}^{(2)}a_2^{(2)}+w_{13}^{(2)}a_3^{(2)}+b_1^{(3)} \\
z_2^{(3)}=w_{21}^{(3)}a_1^{(2)}+w_{22}^{(3)}a_2^{(2)}+w_{23}^{(2)}a_3^{(2)}+b_2^{(3)} \\
a_1^{(3)}=f(z_1^{(3)}) \\
a_2^{(3)}=f(z_2^{(3)})
++++

可以总结出，第stem:[l(2 \le l \le L)]层神经元的状态及激活值为（下面式子是向量表示形式）：

[stem]
++++
\textbf{z}^{(l)}=W^{(l)} \textbf{a}^{(l-1)}+\textbf{b}^{(l)} \\
\textbf{a}^{(l)}=f(\textbf{z}^{(l)})
++++

对于stem:[L]层感知机，网络的最终输出为stem:[\textbf{a}^{(L)}]。前馈神经网络中信息的前向传递过程如下：

[stem]
++++
\textbf{x}=\textbf{a}^{(1)} \rightarrow \textbf{z}^{(2)} \rightarrow \dots \rightarrow \textbf{a}^{(L-1)} \rightarrow \textbf{z}^{(L)} \rightarrow \textbf{a}^{(L)}=y
++++